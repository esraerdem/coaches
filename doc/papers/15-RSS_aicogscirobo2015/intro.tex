\section{Introduction}

Contributions

Different levels of abstractions for the representation of information ...
(no need to add too details at the high level)


Dealing with action failures and incomplete/incorrect model of the environment


Problem

Input: set of possible tasks

Output: execution and monitoring of a behavior (policy) implementing a solution for the most convenient task.




Execution monitoring and interleaving planning and execution are crucial features for an autonomous robot acting in a real environment, specially when human interaction is involved, 
as for the COACHES robots. Indeed, in complex scenarios, it is not possible to model and foresee all the possible situations that may occur and plans generated at planning time, when several information about the real environment are not known, may not be optimal or feasible at execution time.




It is thus necessary to explicitly model and consider possible plan failures and to devise a mechanism that is able to properly reach to these failures.

In this paper, we describe a framework for representing possible causes of action failures and for revising the model of the system, in order to find better plans for the current situation.
