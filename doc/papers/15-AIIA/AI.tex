\section{Artificial Intelligence components}

While the overall software architecture described before integrates several components that are all important for the development of the project, in this paper we focus on the modules that implement a proper integration between Artificial Intelligence and Robotics techniques.
Thus, in this section, we will describe the three main components that allow the robots to: 1) represent and reason about the environment, 2) generate the plan to reach their goals; 3) monitor the execution to overcome failures.



\subsection{Knowledge base representation and reasoning}

%Knowledge based reasoning (semantic map, commonsense reasoning, ...)

The knowledge base (KB) is used to model both static knowledge (e.g., the semantic map of the environment and the common sense information) and the dynamic knowledge (e.g., human activities) coming from different units, such as the perception modules of the architecture, particularly the multi-modal HRI interface and the image processing modules. 
From these information, the reasoning module is able to infer the list of possible tasks to accomplish. This list of tasks is then sent to the decision module (described in the following section) that will compute the policy to accomplish them. 

In this section, we define the main features of the knowledge base used in the project. We first introduce the semantic labels used to describe elements of the world, then predicates that determine relations among these labels, and finally its application to the use case if the project.

\vspace{1em}

\noindent 
\textbf{Semantic labels}

In order to refer to objects and classes of objects in the knowledge base, we introduce a set of labels that will be associated to semantic meanings. 

A first set of these labels are called \emph{Concepts} and they are associated to classes of objects. For example, \emph{Restaurant} is a concept used in the semantic map to denote the class of restaurants in the shopping mall. Concept labels always start with an uppercase letter.
These concepts are organized in a hierarchical way according to the ``is-a'' relation.
In this way, we can express, for example, that the concept \emph{FrenchRestaurant} is a \emph{Restaurant}. 

A second set of labels will be used to denote objects. Each object belongs to a concept implementing the relation ``instance-of''. Object labels always start with a lowercase letter.
Thus, a particular restaurant in the mall will be denoted with an object label \emph{caf\'eMarcel} that will be instance of the concept \emph{FrenchRestaurant}. 

\vspace{1em}

\noindent 
\textbf{Predicates}

Predicates are used to describe relations among the semantic labels. For example, the ``is-a'' and the ``instance-of'' relations can be represented by the corresponding predicates {\tt\bf is-a} and {\tt\bf instance-of}. For example, we can write

\begin{quote}
{\tt\bf is-a}(FrenchRestaurant, Restaurant)\\
{\tt\bf instance-of}(caf\'eMarcel, FrenchRestaurant)\\
\end{quote}

%Sometimes,  the ``is-a'' and the ``instance-of'' relations will be abbreviated respectively by
%the operators $\subset$ and $\in$.
%Thus, the above example can also be described as \emph{FrenchRestaurant} $\subset$ \emph{Restaurant} and \emph{caf\'eMarcel} $\in$ \emph{FrenchRestaurant}.


Predicates are also used to denote properties of objects. For example, given the concepts \emph{Color} and \emph{Dress} and the objects \emph{red} $\in$ \emph{Color} and \emph{dress\_123} $\in$ \emph{Dress}, the predicate 

\begin{quote}
{\tt\bf color}(dress\_123,  red)
\end{quote}

\noindent
will represent the color property \emph{red} of the particular object  \emph{dress\_123}.


\vspace{1em}

\noindent 
\textbf{Example of representation of the environment}

For representing the \emph{Rive de l'orne} shopping mall, we consider different types of areas: shops, restaurants, halls, corridors, rest areas, offices, toilettes, etc. For shops, services and restaurants we consider different categories:
\begin{itemize}
\item {\it Shop categories}: dress shop , women dress shop, kid dress shop, men dress shop, makeup store, store perfume, sport store, etc.
\item {\it Restaurant categories}: French, Japanese, Chinese, Italian, Oriental, African, fast-food, etc.
\item {\it Service categories}: security, information, health-care, etc.
\end{itemize}

All these areas are represented as concepts that are grouped in a more general concept \emph{Area}. The hierarchy of these areas will be defined through the ``is-a'' relation of the semantic labels described before.

Doors are also considered as connections of these areas. \emph{Door} is a concept containing door objects and connections of areas through doors are represented with the {\tt\bf connect} predicate (see also below).

\begin{quote}
{\tt\bf connect}(door12, area1, area2)
\end{quote}

\noindent
where \emph{door12} $\in$ \emph{Door} \emph{area1}, \emph{area2} $\in$ \emph{Area}  are objects belonging to the corresponding concepts. Moreover, the status of the door can be expressed with a predicate {\tt\bf open}. For example,

\begin{quote}
{\tt\bf open}(door12) \\
\end{quote}





\subsection{Planning under uncertainty}

In this section we describe the Markov Decision Process (MDP) used to model the \coaches planning domain and the algorithm implemented for computing the optimal policy.
In this algorithm a tabu-list of actions is used to choose actions to be inserted in the policy.
This tabu-list is built and updated by the Model updater module described below in this section.


\todo{MDP planner with tabu-list ...}





\subsection{Plan execution and monitoring}


Plan execution monitoring and interleaving planning and execution are crucial features for an autonomous robot acting in a real environment, specially when human interaction is involved, 
as for the \coaches robots. Indeed, in complex scenarios, it is not possible to model and foresee all the possible situations that may occur, consequently plans generated off-line (i.e., before the actual execution of the task), when several information about the real environment are not known, may not be optimal or feasible at execution time.

It is thus necessary to explicitly model and consider possible plan failures and to devise a mechanism that is able to properly react to these failures. Moreover, on-line replanning (i.e., planning after plan failures) may not be feasible when the model itself is inaccurate, since the same cause of the plan failure (typically a non-modeled feature of the environment) will likely occur also in next executions.

To this end, we have defined a plan execution and monitoring framework composed by three modules: a planner (as described in the previous section), an executor, and a model updater. The three modules cooperate during the execution of a complex task for a robot and provide for a feedback mechanism from execution to planning.
More specifically, the following interactions are devised:
1) the planner notifies on-line to the executor the best plan (policy) to be executed according to the current model of the world; 2) the executor executes this plan (policy) and determines success or failures of the actions; 3) each failure is reported to the model updater that will follow some rules (either automatic domain dependent or manual domain dependent) to modify the current model, so that the planner can generate a new plan that is more suitable for the current situation as detected by the executor.

The execution module is based on the Petri Net Plan (PNP) formalism \cite{ZiIo11PNP}. 

\todo{PNP ...}



The two main components of this process will be described in the rest of this section:
1) Policy to PNP transformation; 2) Model updater.

\vspace{1em}
\noindent
{\bf Policy to PNP transformation}

The policy generated by the MDP planner (described in the previous section) is \todo{automatically transformed in a PNP ...}


PNP includes interrupt constructs allowing to determine action and plan failures.
When some execution condition for an action is not met, then an interrupt is activated
suspending the execution of the current action. The flow of execution of the plan can follow one of the two following lines: 1) \emph{internal recovery procedure}, when the current plan itself contains a recovery behavior (i.e., a sub-plan or portion of the plan) for dealing with this failure; 2) \emph{plan failure}, when the current plan is not able to deal with this kind of failure.

In the latter case, the executor sends to the Model updater module the following information:
1) action failed, 2) condition that was checked to determine action failure, 3) status of the plan (that can contain additional conditions useful for diagnosis of the failure).
Given this input, the Model updater module (described in the next paragraph) modifies the MDP model of the domain and activates a new planning procedure to generate a new plan (policy) that aims at avoiding at least the failure cause just occurred.


\noindent
{\bf Model update}

The problem of updating a planning model, given the feedback of the execution of the plan, is very relevant for actual application of planning techniques to real problems, but, to the best of our knowledge, this problem has not been investigated explicitly and a general solution does not exists.

At this moment, we have implemented a simple method that build and maintains a tabu list of actions to be selected in the MDP planning process.
More specifically, ...






